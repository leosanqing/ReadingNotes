<map>
		<node ID="root" TEXT="数学之美">		<node TEXT="文字和语言，信息和数字" ID="3811672288e1d2028" STYLE="bubble" POSITION="right">
		<node TEXT="翻译能达成的条件" ID="31672289463404c" STYLE="fork">
		<node TEXT="不同的文字系统在记录信息上的能力是等价的" ID="1fe1672289a086016" STYLE="fork">
		</node>
		<node TEXT="文字只是载体，而非信息本身" ID="245167228a4ec60f1" STYLE="fork">
		</node>
		</node>
		<node TEXT="罗塞塔石碑的指导意义" ID="4016726b0501f0f6" STYLE="fork">
		<node TEXT="信息冗余是信息安全的保障" ID="39116726b09c8605c" STYLE="fork">
		</node>
		<node TEXT="语言的数据，即语料，尤其是双语或者多语语料对翻译至关重要，是我们从事机器翻译研究的基础" ID="2dd16726b0e961165" STYLE="fork">
		</node>
		</node>
		<node TEXT="罗马数字，小数字出现在大数字前为减，右边为加。如Ⅳ 5-1  Ⅶ 5+2" ID="15216726b816f50f6" STYLE="fork">
		</node>
		<node TEXT="从象形文字到楔形文字，从具体到抽象。常用字笔画少，生僻字笔画多，完全符合信息论中的最短编码原理；" ID="13d16726b9a7c0146" STYLE="fork">
		</node>
		</node>
		<node TEXT="自然语言处理——从规则到统计" ID="1d1167270b90ab017" STYLE="bubble" POSITION="right">
		<node TEXT="图灵测试，验证机器是否有智能" ID="80167270bdae201" STYLE="fork">
		<node TEXT="让人和机器进行交流，如果人无法判断自己交流的对象是人还是机器，就说明这个机器有智能了" ID="fc167270c7e7800a" STYLE="fork">
		</node>
		</node>
		<node TEXT="误区  " ID="381167270e072c0c8" STYLE="fork">
		<node TEXT="20世纪50年代到70年代" ID="168167270e3d44084" STYLE="fork">
		</node>
		<node TEXT="基于规则的语言处理" ID="79167270e919903a" STYLE="fork">
		</node>
		<node TEXT="原因" ID="2f7167270fd65d007" STYLE="fork">
		<node TEXT="因为陷入了人对于自然语言的认知" ID="3b0167270edeed0c3" STYLE="fork">
		</node>
		<node TEXT="认为想让机器完成翻译或者语音识别，必须先让计算机理解自然语言，而这必须先让计算机有智能" ID="95167270fe4f6169" STYLE="fork">
		</node>
		<node TEXT="后来被称为&quot;鸟飞派&quot;" ID="37b167271161bb0bf" STYLE="fork">
		</node>
		<node TEXT="我们只需要理解空气动力学，就能像鸟一样飞，而不是依靠仿生学" ID="31f1672711aee70e2" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="1970年之后，基于统计学的处理方法诞生" ID="33f167271272100dc" STYLE="fork">
		<node TEXT="近30年取得突破性的发展" ID="2a916727131acb165" STYLE="fork">
		</node>
		</node>
		<node TEXT="但是这两者之争扔持续了15年" ID="a31672713a6ed0f3" STYLE="fork">
		<node TEXT="新生的需要一定时间成熟" ID="1231672713e524155" STYLE="fork">
		</node>
		<node TEXT="必须等原有的一批看科学家退休" ID="181167271413ae0e1" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="统计语言模型" ID="26f16729f0893909c" STYLE="bubble" POSITION="right">
		<node TEXT="马尔科夫模型" ID="19716729f5546e158" STYLE="fork">
		<node TEXT="只和前一个单词有关的为二元模型，和前面n个相关的为n元模型" ID="ae16729f67005172" STYLE="fork">
		</node>
		<node TEXT="一般为3元模型，Google采用4元模型" ID="26216729f7566c13f" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="分词" ID="331672c07c42d183" STYLE="bubble" POSITION="right">
		<node TEXT="对于西方来说，词之间有分界符。一些亚洲语言，词之间没有明显的分界符。" ID="a31672c0d5fba0a2" STYLE="fork">
		</node>
		<node TEXT="因此需要对句子进行分词，才能做进一步自然语言处理" ID="761672c0829db09f" STYLE="fork">
		</node>
		<node TEXT="现在由于手机平板的出现，西方国家也有手写体，这时就需要借鉴中文分词法" ID="2311672c0d73f8125" STYLE="fork">
		</node>
		</node>
		<node TEXT="隐含马尔科夫模型" ID="3a71672fdc0337172" STYLE="bubble" POSITION="right">
		<node TEXT="通信的本质是编解码和传输的过程" ID="d51672fdc3452162" STYLE="fork">
		</node>
		<node TEXT="雅各布森通信六个要素" ID="37d1673019a4580cd" STYLE="fork">
		<node TEXT="发送者(信息源)" ID="3121673019fef204a" STYLE="fork">
		</node>
		<node TEXT="信道" ID="151167301a43d608b" STYLE="fork">
		</node>
		<node TEXT="接收者，" ID="3f167301aa404088" STYLE="fork">
		</node>
		<node TEXT="信息" ID="3d2167301a63f80b1" STYLE="fork">
		</node>
		<node TEXT="上下文" ID="10c167301aa9220df" STYLE="fork">
		</node>
		<node TEXT="编码" ID="231167301ab8d3008" STYLE="fork">
		</node>
		</node>
		<node TEXT="19世纪，概率论的发展从对(相对静态的)随机变量的研究发展到对随机变量的时间序列s1,s2,s3,...,st,...，即随机过程的研究" ID="1d1167301af6ea168" STYLE="fork">
		</node>
		<node TEXT="隐含马尔可夫模型最早的成功应用是语音识别。李开复博士坚持采用隐含马尔可夫模型的框架，成功研发出世界上第一个大词汇量连续语音识别系统Sphinx" ID="2da167301d5763132" STYLE="fork">
		</node>
		<node TEXT="隐含马尔可夫模型有三个基本问题" ID="1651673023133a075" STYLE="fork">
		<node TEXT="给定一个模型，如何计算某个特定的输出序列的概率( Forward-Backword算法)" ID="326167302373de068" STYLE="fork">
		</node>
		<node TEXT="给定一个模型和某个特定的输出序列，如何找到最可能产生这个输出的状态序列(维特比算法)" ID="221673023f5f4052" STYLE="fork">
		</node>
		<node TEXT="给定足够量的观测数据，如何估计隐含马尔可夫模型的参数(鲍姆-韦尔奇算法)" ID="1616730256bc110a" STYLE="fork">
		</node>
		</node>
		<node TEXT="隐含马尔可夫模型最初应用于通信领域，继而推广到语音和语言处理中，成为连接自然语言处理和通信的桥梁。也是机器学习的主要工具之一。和所有的机器学习的模型一样，他需要一个训练算法(鲍姆-韦尔奇算法)和使用时的解码算法(维特比算法)" ID="2531673027681517f" STYLE="fork">
		</node>
		</node>
		<node TEXT="PageRank" ID="271673e20919d0a4" STYLE="bubble" POSITION="right">
		<node TEXT="将互联网看成一个整体" ID="21673e20a97418d" STYLE="fork">
		</node>
		<node TEXT="一个网页被很多其他网页所链接，说明他受到承认和依赖，那么他的排名就高" ID="2f41673e210596158" STYLE="fork">
		</node>
		<node TEXT="权重的想法应该来自佩奇，破除后面迭代问题来自布林" ID="191673e211a51142" STYLE="fork">
		</node>
		<node TEXT="后来出现并行计算工具, MapReduce,由原来的半自动化变成全自动化" ID="1e91673e212f78197" STYLE="fork">
		</node>
		</node>
		<node TEXT="TF-IDF" ID="27c1673e215c9b0de" STYLE="bubble" POSITION="right">
		<node TEXT="影响搜索质量的因素" ID="34f1673e21707803b" STYLE="fork">
		<node TEXT="完备的索引" ID="2d41673e21a20b02b" STYLE="fork">
		</node>
		<node TEXT="对网页质量的度量 ，如pageRank" ID="2671673e21c98d109" STYLE="fork">
		</node>
		<node TEXT="用户偏好" ID="3781673e21e56007d" STYLE="fork">
		</node>
		<node TEXT="确定一个网页和某个查询的相关性" ID="3981673e21fbab001" STYLE="fork">
		</node>
		</node>
		<node TEXT="TF-IDF" ID="1d31673e22126f0bf" STYLE="fork">
		<node TEXT="单文本词频/逆文本频率指数" ID="36f1673e22293b0a" STYLE="fork">
		</node>
		<node TEXT="为每一个词给一个权重，这个权重设定满足的条件" ID="931673e224a8610b" STYLE="fork">
		<node TEXT="一个词预测主题的能力越强，权重越大。如原子能＞应用" ID="3521673e225e570f4" STYLE="fork">
		</node>
		<node TEXT="停用词的权重为0" ID="351673e2280da01e" STYLE="fork">
		</node>
		</node>
		<node TEXT="最早是由剑桥大学 斯巴克·琼斯提出的，但是并没有解释为啥是对数函数而不是其他函数。后来剑桥大学的罗宾逊也解释，但是没有说清。后来康奈大学的萨尔顿解释清楚了这个在信息检索中的用途" ID="1361673e22b0a70ba" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="信息的度量和作用" ID="2c167306b731a101" STYLE="bubble" POSITION="right">
		<node TEXT="信息熵" ID="2df167306ba79a094" STYLE="fork">
		<node TEXT="一条信息的信息量与其不确定性有些直接的关系" ID="121167306bd027038" STYLE="fork">
		</node>
		<node TEXT="信息熵就是度量信息，量化信息作用" ID="1c9167306c8040063" STYLE="fork">
		</node>
		</node>
		<node TEXT="不同语言的冗余度差别很大，而汉语在所有语言中冗余度是相对小的" ID="345167306d171617d" STYLE="fork">
		</node>
		<node TEXT="信息的作用——消除不确定性" ID="10b167306eecf9005" STYLE="fork">
		<node TEXT="如果没有信息，任何公式或者数字的游戏都无法排除不确定性" ID="335167306f4efb0fc" STYLE="fork">
		</node>
		<node TEXT="当引入相关信息，就能减少不确定性" ID="e11673072872b04b" STYLE="fork">
		</node>
		<node TEXT="从搜索引擎上来看" ID="27016730710d56094" STYLE="fork">
		<node TEXT="如果只给定一个信息&quot;中国&quot;，那么会有很多相关信息，你并不能确定哪些是你需要的，但是再多引入一些信息，那么可能在页面的前几个就是你需要的信息了" ID="2ae16730713ee9102" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="互信息" ID="1c4167310be7e90c" STYLE="fork">
		<node TEXT="香农在信息论中提出了这个概念作为两个随机事件&quot;相关性&quot;的量化度量" ID="12d167310c2c950d4" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="贾里尼克和现代语言处理" ID="38916731262d38158" STYLE="bubble" POSITION="right">
		<node TEXT="年少教育" ID="10916731270275066" STYLE="fork">
		<node TEXT="小学生和中学生其实没必要花那么多时间读书，而他们的社会经验，生活能力以及在那时树立起的志向将帮助他们的一生" ID="2a216731279976107" STYLE="fork">
		</node>
		<node TEXT="大学以后理解能力增强，很多中学努力学的东西，可能只需要十之一二的时间就能学会" ID="182167312865300cd" STYLE="fork">
		</node>
		<node TEXT="学习是终生的事" ID="bd16731296b7918b" STYLE="fork">
		</node>
		<node TEXT="书本的内容可以早学，我可以晚学，但是错过了成长阶段却是无法补回来的" ID="2401673129e31615e" STYLE="fork">
		</node>
		</node>
		<node TEXT="贾里尼克在约翰·霍普金斯大学建立了世界著名的CLSP实验室" ID="94167312b788713a" STYLE="fork">
		</node>
		<node TEXT="做事严谨，学生淘汰率高，但是却为每一个学生争取最大便利。闲不住，70多岁仍每天按时上班" ID="81167312c8186035" STYLE="fork">
		</node>
		</node>
		<node TEXT="布尔代数和搜索引擎" ID="3d7167313e7fe400a" STYLE="bubble" POSITION="right">
		<node TEXT="搜索 原子能 应用，不包含原子弹" ID="300167313eb93e0bd" STYLE="fork">
		<node TEXT="将前两个搜索结果与，并且和第三个结果非。得到搜索结果" ID="2a1167313fa09b0e5" STYLE="fork">
		</node>
		</node>
		<node TEXT="布尔代数将逻辑和数学合二为一，给了一个看待世界的全新视角" ID="36216731404790067" STYLE="fork">
		</node>
		</node>
		<node TEXT="有限状态机和动态规划" ID="5b1673e237cee07d" STYLE="bubble" POSITION="right">
		<node TEXT="解决输入路径匹配，自动识别输入地址" ID="2cc1673e23868c18b" STYLE="fork">
		<node TEXT="能识别错别字" ID="a21673e23d69a038" STYLE="fork">
		</node>
		<node TEXT="能识别不太标准的语句" ID="3971673e23f3b610f" STYLE="fork">
		</node>
		</node>
		<node TEXT="动态规划解决地图中最短路径" ID="351673e24067b0d4" STYLE="fork">
		</node>
		</node>
		<node TEXT="GoogleAK-47的设计者阿米特·辛格博士" ID="3961673e245984197" STYLE="bubble" POSITION="right">
		<node TEXT="简单即是真理" ID="2e91673e2463c2059" STYLE="fork">
		</node>
		<node TEXT="要求对于搜索质量提高的改进方法需要能说清楚理由，必须能对机器学习出来的参数和公式给出合理的解释，否则不能上线" ID="3611673e2479640ec" STYLE="fork">
		</node>
		<node TEXT="先解决用户80%的问题，再解决剩下的20%" ID="801673e24b23c0c1" STYLE="fork">
		</node>
		</node>
		<node TEXT="余弦定理" ID="13d1673e2520450f3" STYLE="bubble" POSITION="right">
		<node TEXT="对文本进行分类" ID="3b31673e253ced118" STYLE="fork">
		<node TEXT="计算文章中所有实词的TF-IDF值，" ID="3db1673e2551ff04e" STYLE="fork">
		</node>
		<node TEXT="将这些词按照对应的实词在词汇表中的位置依次排列，得到一个向量" ID="8d1673e256a710e3" STYLE="fork">
		</node>
		<node TEXT="利用余弦定理计算两个向量夹角" ID="36d1673e257e070a3" STYLE="fork">
		</node>
		<node TEXT="夹角越小，两个文章越相似" ID="691673e258fc80a5" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="矩阵运算和文本处理的两个分类问题" ID="3601673e25b57a035" STYLE="bubble" POSITION="right">
		<node TEXT="比余弦定理时间短的粗分类——奇异值分解" ID="1cf1673e25cebb124" STYLE="fork">
		<node TEXT="一开始将所有信息列入一个矩阵，每一个值表示TF-IDF" ID="36a1673e277786029" STYLE="fork">
		</node>
		<node TEXT="将一个矩阵分解为三个小矩阵相乘" ID="1151673e278fdd094" STYLE="fork">
		</node>
		<node TEXT="第一个矩阵的每一行表示一个词，每一列表示一个语义相近的词" ID="441673e27a198023" STYLE="fork">
		</node>
		<node TEXT="最后一个矩阵是对文本分类的结果，每一列对应一篇文章，每一行对应一个主题" ID="36d1673e27b382192" STYLE="fork">
		</node>
		<node TEXT="中间的矩阵表示词的类和文章的类之间的相关性" ID="4b1673e27c3520a4" STYLE="fork">
		</node>
		<node TEXT="并行算法由后来Google中国的张智威博士带领的团队解决" ID="1161673e27d204082" STYLE="fork">
		</node>
		</node>
		<node TEXT="一般先进行奇异值分解粗分类，再进行余弦定理细分类" ID="3331673e27e22d038" STYLE="fork">
		</node>
		</node>
		<node TEXT="图论和网络爬虫" ID="1d3167314d37e502" STYLE="bubble" POSITION="right">
		<node TEXT="图论的起源可以追溯到欧拉时代" ID="d6167314d70e719" STYLE="fork">
		<node TEXT="论证了如果一个图能够从一个顶点出发，每条边不重复地遍历回到这个顶点，那么每一个顶点的度必须为偶数" ID="3c6167314ddfc00c6" STYLE="fork">
		</node>
		</node>
		<node TEXT="网络爬虫大致的细节" ID="1b3167314f8ebf11e" STYLE="fork">
		<node TEXT="使用BFS还是DFS，大部分用BFS" ID="2c4167314fdb1e00b" STYLE="fork">
		</node>
		<node TEXT="页面的分析和URL的提取" ID="2e7167315080460b8" STYLE="fork">
		</node>
		<node TEXT="记录哪些网页已经下载过的小本本——URL表" ID="1a01673150cfc90de" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="信息指纹及其应用" ID="25316735678d78139" STYLE="bubble" POSITION="right">
		<node TEXT="任何一段信息（图像，语音，文字），都可以对应一个不太长的随机数，作为区别这段信息和其他信息的指纹" ID="26d16735689864137" STYLE="fork">
		</node>
		<node TEXT="产生的这段指纹，只要算法设计得好，任意两段信息的指纹都很难重复" ID="12f1673567b34d031" STYLE="fork">
		</node>
		<node TEXT="使用伪随机数产生算法（MD5, SHA-1），将其生成为一段定长（128或160)的随机二进制数" ID="363167356b4974142" STYLE="fork">
		</node>
		<node TEXT="用途" ID="305167356cb79d003" STYLE="fork">
		<node TEXT="网页搜索查询两个用词是否完全相同" ID="196167356f5cee198" STYLE="fork">
		</node>
		<node TEXT="判断两个网页是否基本相同，是否存在抄袭" ID="31b1673571f1cd002" STYLE="fork">
		</node>
		<node TEXT="YouTube反作弊" ID="2d216735725ccc007" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="密码学的基本原理" ID="13a1673572a7520ba" STYLE="bubble" POSITION="left">
		<node TEXT="可追溯至两千年前，凯撒使用密码传送情报" ID="9d1673572d02307e" STYLE="fork">
		</node>
		<node TEXT="根据信息论，密码学的最高境界是敌方在截取密码后，对我方的所知没有任何增加，用信息论的术语就是信息量没有增加" ID="1ea1673574be66165" STYLE="fork">
		</node>
		<node TEXT="一般来讲，密码之间分布均匀并且统计独立时，提供的信息最少" ID="8e16735761eb7119" STYLE="fork">
		</node>
		<node TEXT="公开密钥的好处" ID="3c5167357bfa9f09" STYLE="fork">
		<node TEXT="简单" ID="31167357c57d50f6" STYLE="fork">
		</node>
		<node TEXT="可靠" ID="364167357c691505c" STYLE="fork">
		</node>
		<node TEXT="灵活" ID="312167357c719a051" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="搜索引擎的反作弊和搜索结果权威性" ID="24416735775e25132" STYLE="bubble" POSITION="left">
		<node TEXT="搜索中的作弊可以理解为通信中的噪音" ID="25e167360a68a40b4" STYLE="fork">
		</node>
		<node TEXT="通信中解决噪音干扰的模型在搜索反作弊依然适用" ID="3da167357cebd3093" STYLE="fork">
		<node TEXT="从信息源出发，加强通信（编码）自身的抗干扰能力" ID="271167360b307c06d" STYLE="fork">
		<node TEXT="利用余弦定理，计算网站的出链向量" ID="8e167360c6a3e0a4" STYLE="fork">
		</node>
		</node>
		<node TEXT="从传输来看，过滤掉噪音，还原信息" ID="2d3167360b98f204c" STYLE="fork">
		<node TEXT="图论。" ID="26616736125a57188" STYLE="fork">
		<node TEXT="如果有几个节点两两互相都连接在一起，他们被称为一个Clique。因为需要这样提高自己的排名" ID="15167361292d40a6" STYLE="fork">
		</node>
		</node>
		</node>
		</node>
		<node TEXT="搜索结果的权威性" ID="27616736137ab711f" STYLE="fork">
		<node TEXT="pageRank只能从链接的网络质量数量来判断网页内容质量。但是像很多八卦网站，内容未必权威" ID="b51673613add70b1" STYLE="fork">
		</node>
		<node TEXT="如何度量" ID="1731673614ea7d15d" STYLE="fork">
		<node TEXT="引入一个新的概念  &quot;提及&quot;( Mention)" ID="36316736162441069" STYLE="fork">
		<node TEXT="但是这个隐含在文章的自然语句中，需要通过自然语言处理方法分析，即使有好的算法，计算量仍然很大" ID="3e816736172b9c0d5" STYLE="fork">
		</node>
		<node TEXT="而且提及的组织，机构必须是和主题相契合的" ID="3e216736181d02125" STYLE="fork">
		</node>
		<node TEXT="拥有云计算大数据技术，计算权威才有可能" ID="12c16736194a15087" STYLE="fork">
		</node>
		</node>
		<node TEXT="计算权威的步骤" ID="1e91673616b1b61" STYLE="fork">
		<node TEXT="对每一个网页正文(包括标题)中的每一句话进行句法分析，然后找出涉及到主题的短语，以及对信息源的描述" ID="1ef16736170ec00e" STYLE="fork">
		</node>
		<node TEXT="利用互信息，找到主题短语和信息源的相关性" ID="115167361ac1aa0a" STYLE="fork">
		</node>
		<node TEXT="需要对主题短语进行聚合，用矩阵运算的方法" ID="139167361b5d74051" STYLE="fork">
		</node>
		<node TEXT="需要对一个网站中的网页进行聚合，比如吧一个网站下面的网页按照子域或者子目录进行聚合" ID="3b2167361bf9fa088" STYLE="fork">
		</node>
		</node>
		</node>
		</node>
		</node>
		<node TEXT="数学模型的重要性" ID="1fe16736270416067" STYLE="bubble" POSITION="left">
		<node TEXT="对于很多问题，完美的数学模型应当是最简单的" ID="92167362737030e8" STYLE="fork">
		</node>
		<node TEXT="托勒密" ID="30f16736284aa801d" STYLE="fork">
		<node TEXT="2000多年前的罗马时代" ID="50167362f0a23039" STYLE="fork">
		</node>
		<node TEXT="计算出诸多天体运行轨迹，于天文学作用堪比欧几里得之于几何学，牛顿之于物理学" ID="34d16736287dca171" STYLE="fork">
		</node>
		<node TEXT="但是他提出的是地心说" ID="fa167362a4b1a166" STYLE="fork">
		</node>
		<node TEXT="贡献" ID="3d167362a78a3148" STYLE="fork">
		<node TEXT="发明球坐标" ID="88167362aa00b128" STYLE="fork">
		</node>
		<node TEXT="定义了包括赤道和零度经线在内的经纬线" ID="9c167362acb1304a" STYLE="fork">
		</node>
		<node TEXT="提出了黄道" ID="244167362b5bff06d" STYLE="fork">
		</node>
		<node TEXT="发明了弧度制" ID="190167362b754b108" STYLE="fork">
		</node>
		<node TEXT="对地心说模型的完善" ID="249167362ba9be09d" STYLE="fork">
		<node TEXT="采用40–60个在大圆上面套小圆的方法，精确计算出所有行星的运行轨迹" ID="1f3167362cce2c17f" STYLE="fork">
		</node>
		</node>
		<node TEXT="制定了儒略历" ID="124167362c780113f" STYLE="fork">
		<node TEXT="每年为365天，每四年增加一个闰年" ID="2f4167362e6ece00e" STYLE="fork">
		</node>
		<node TEXT="后来经过1500年，误差多出了10天，最后教皇格里高利在儒略历的基础上删除10天，并将每世纪最后一年的闰年改成平年" ID="366167362f9f80024" STYLE="fork">
		</node>
		</node>
		</node>
		</node>
		<node TEXT="结论" ID="37167362c9e9d15b" STYLE="fork">
		<node TEXT="正确的数学模型应当在形式上是简单的(托勒密显然太复杂)" ID="21673631e28a139" STYLE="fork">
		</node>
		<node TEXT="一个正确的模型一开始可能不如一个精雕细琢过的错误模型(哥白尼的日心说)" ID="31a1673632ddf50ac" STYLE="fork">
		</node>
		<node TEXT="大量准确的数据对研发很重要" ID="3961673633e2c300e" STYLE="fork">
		</node>
		<node TEXT="正确的模型可能受噪音干扰，而显得不准确；这时不应该用一种凑合的修正方法加以弥补，而是要找到噪音的根源，也许能通往重大的发现" ID="21a1673634116e165" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="最大熵模型" ID="22516739275cb418b" STYLE="bubble" POSITION="left">
		<node TEXT="原理" ID="237167392775fe0c" STYLE="fork">
		<node TEXT="对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设" ID="4b167392809250a1" STYLE="fork">
		</node>
		<node TEXT="不要把所有鸡蛋放在一个篮子里。当我们我们遇到不确定性时，就要保留各种可能性" ID="d71673929a2a30be" STYLE="fork">
		</node>
		</node>
		<node TEXT="最大熵模型在形式上是最漂亮、最完美的统计模型。" ID="11167392a8f35108" STYLE="fork">
		</node>
		<node TEXT="应用" ID="362167392b0cce09d" STYLE="fork">
		<node TEXT="自然语言处理" ID="2af167392b152b057" STYLE="fork">
		<node TEXT="拉纳帕提做出来当时世界上最好的词性标识系统和句法分析器" ID="bb167392b7601031" STYLE="fork">
		</node>
		</node>
		<node TEXT="金融" ID="31167392b29ee0f2" STYLE="fork">
		<node TEXT="贾里尼克和达拉·皮垂兄弟还有做语音识别系统的同事到文艺复兴技术公司" ID="20167392d2a58005" STYLE="fork">
		</node>
		<node TEXT="1988年创立至今，该基金的净回报率高达34%；08年金融危机，全球股市暴跌，回报率高达80%" ID="ee167392e45c20ba" STYLE="fork">
		</node>
		</node>
		</node>
		</node>
		<node TEXT="拼音输入法的数学原理" ID="ed1673967542a152" STYLE="bubble" POSITION="left">
		<node TEXT="早期汉字输入法" ID="35c16739677720106" STYLE="fork">
		<node TEXT="使用拼音，后来改成双拼" ID="28d167443e2da3175" STYLE="fork">
		</node>
		<node TEXT="虽然敲击的次数少了，但是严重影响思维。而且很难记住" ID="2d4167443e62c2119" STYLE="fork">
		</node>
		</node>
		<node TEXT="后来，使用拼音" ID="220167443fc6f617" STYLE="fork">
		<node TEXT="不需要专门练习" ID="34c167444037c503a" STYLE="fork">
		</node>
		<node TEXT="输入自然，不会中断思维，找键时间短" ID="771674440d16e159" STYLE="fork">
		</node>
		<node TEXT="因为编码长，有信息冗余量，容错性好" ID="395167444362040ed" STYLE="fork">
		</node>
		</node>
		<node TEXT="香农第一定理" ID="1c61674443db4f09a" STYLE="fork">
		<node TEXT="对于一个信息，任何编码的长度都不小于他的信息熵" ID="7416744442750067" STYLE="fork">
		</node>
		</node>
		<node TEXT="拼音转汉字的算法" ID="461674448594105e" STYLE="fork">
		<node TEXT="动态规划" ID="c1167444e2dd40b6" STYLE="fork">
		</node>
		<node TEXT="与导航相似" ID="277167444e509b0b3" STYLE="fork">
		</node>
		<node TEXT="每一个音节可以对应多少个汉字，把一个拼音串对应的汉字从左到右连起来，就是一张有向图，她被称为网格图" ID="11a167444ed90c0a7" STYLE="fork">
		</node>
		<node TEXT="拼音输入法就是要根据上下文在给定拼音条件下找到一个最优的句子，对应到图中就是要找从起点到终点的一条最短路径" ID="19a16744505c8b0ac" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="自然语言处理的教父马库斯" ID="9e16744572c2304a" STYLE="bubble" POSITION="left">
		<node TEXT="运用自己的影响力，推动自然科学基金会和DARPA出资立项，联络了多所大学和研究机构，建立了数百个标准的语料库组织(LDC)" ID="32916744576c1f044" STYLE="fork">
		</node>
		<node TEXT="他的影响力很大一部分是靠弟子传播出去的" ID="295167445c914e14" STYLE="fork">
		<node TEXT="管理相对宽松，所以很多弟子性格迥异。凭借自己的经验和见识，避免自己的学生做无用功" ID="27416744603c1a097" STYLE="fork">
		</node>
		<node TEXT="迈克尔·柯林斯" ID="395167445e97c8095" STYLE="fork">
		<node TEXT="追求完美" ID="326167446032dd08e" STYLE="fork">
		</node>
		<node TEXT="做出了世界上最好的分析器" ID="fd167446170ff014" STYLE="fork">
		</node>
		</node>
		<node TEXT="艾里克·布莱尔" ID="e8167445edc680a2" STYLE="fork">
		<node TEXT="简单才美" ID="c1674461b74204d" STYLE="fork">
		</node>
		<node TEXT="基于变换规则的机器学习方法" ID="1671674462330a0ff" STYLE="fork">
		</node>
		</node>
		<node TEXT="大卫·雅让斯基" ID="296167445f3fb014" STYLE="fork">
		</node>
		<node TEXT="拉纳帕提" ID="12167445fa5310d2" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="布隆过滤器" ID="2291675f9e1b2a02b" STYLE="bubble" POSITION="left">
		<node TEXT="一个很长的二进制向量和一系列随机映射函数" ID="7c1675f9e5af6192" STYLE="fork">
		</node>
		<node TEXT="步骤" ID="34f1675fa0557b032" STYLE="fork">
		<node TEXT="先建立一个很长的二进制向量，然后用随机数产生器产生8个信息指纹，" ID="2221675fa173c7008" STYLE="fork">
		</node>
		<node TEXT="再用一个随机数产生器把这8个信息指纹映射到二进制比特位中的8个自然数，" ID="3131675fa299b4119" STYLE="fork">
		</node>
		<node TEXT="把这8个位置的比特位全部设置为1" ID="1f21675fa2937d09c" STYLE="fork">
		</node>
		<node TEXT="之后再用相同的随机数产生器对邮件地址进行比对" ID="34f1675fa2b909001" STYLE="fork">
		</node>
		</node>
		<node TEXT="特点" ID="31c1675fa421f203e" STYLE="fork">
		<node TEXT="不会漏掉黑名单中的任何一个" ID="1021675fa432a1106" STYLE="fork">
		</node>
		<node TEXT="但是会误杀" ID="36b1675fa468720f3" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="贝叶斯" ID="5516755e4c62a0e" STYLE="bubble" POSITION="left">
		<node TEXT="贝叶斯是马尔科夫链的拓展，马尔科夫链是贝叶斯的特例" ID="1b016755e4ee05075" STYLE="fork">
		</node>
		<node TEXT="计算概率" ID="3c81675fa5b3d6038" STYLE="fork">
		</node>
		<node TEXT="谷歌工程师利用贝叶斯建立了 Phil cluster" ID="28c1675fa5cc9704b" STYLE="fork">
		<node TEXT="前期数据不够，模型不好" ID="15a1675fa6972d05e" STYLE="fork">
		</node>
		<node TEXT="后期改进，并更名为Rephil" ID="1581675fa6c0a7035" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="条件随机场、文法分析器" ID="2571675fc694da0d3" STYLE="bubble" POSITION="left">
		<node TEXT="文法分析" ID="28f1675fc6ad4c133" STYLE="fork">
		<node TEXT="演变" ID="21a1675fc713b8139" STYLE="fork">
		<node TEXT="由一开始基于规则变成基于统计" ID="2081675fc724dd0c1" STYLE="fork">
		</node>
		<node TEXT="尤金·查尼亚克搭建了桥梁" ID="3c41675fc7667d10f" STYLE="fork">
		</node>
		<node TEXT="后来马库斯的高足拉纳帕提又建立了新的统计方法" ID="1d41675fc8b5cc098" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="条件随机场" ID="2c516779a34ead006" STYLE="fork">
		<node TEXT="条件随机场是马尔可夫模型的一种拓展" ID="14816779a38dc7169" STYLE="fork">
		</node>
		</node>
		<node TEXT="条件随机场应用" ID="b016779a41bcd135" STYLE="fork">
		<node TEXT="文法分析器" ID="3b016779a445f604c" STYLE="fork">
		</node>
		<node TEXT="预防犯罪" ID="3b016779a4569e05a" STYLE="fork">
		</node>
		<node TEXT="机器学习" ID="19f16779a4a4b10a9" STYLE="fork">
		</node>
		<node TEXT="模式识别" ID="17816779a4b22b0ae" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="维特比和维特比算法" ID="2ea16779a4ce5a111" STYLE="bubble" POSITION="left">
		<node TEXT="维特比" ID="1c716779a4f4ba058" STYLE="fork">
		<node TEXT="创立了高通公司，3G的CDMA" ID="3ab16779a51c66019" STYLE="fork">
		</node>
		<node TEXT="发明维特比算法" ID="4516779a54b3a17d" STYLE="fork">
		</node>
		</node>
		<node TEXT="维特比算法" ID="25416779a667df112" STYLE="fork">
		<node TEXT="动态规划算法" ID="26a16779a6ad3015b" STYLE="fork">
		</node>
		</node>
		<node TEXT="CDMA技术" ID="a116779a6d930135" STYLE="fork">
		<node TEXT="3G移动通信的基础" ID="15a16779a8ceae172" STYLE="fork">
		</node>
		<node TEXT="之前的频分多址和时分多址" ID="28716779a944b3105" STYLE="fork">
		</node>
		<node TEXT="因为是根据密码进行加密和解密，所以被称为码分多址" ID="12d16779aa2d8b061" STYLE="fork">
		</node>
		<node TEXT="只需要通过密码过滤掉无法解码的信号，留下和自己密码对应的信号即可" ID="14a16779aac5d5063" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="期望最大化算法——上帝的算法" ID="18616779abd326057" STYLE="bubble" POSITION="left">
		<node TEXT="步骤" ID="18016779ac1db309" STYLE="fork">
		<node TEXT="随机选取k个点，作为起始的中心" ID="20916779ad8df30a7" STYLE="fork">
		</node>
		<node TEXT="计算所有点到这些中心的距离，将这些点归到最近的一类中" ID="5a16779ae683317c" STYLE="fork">
		</node>
		<node TEXT="重新计算每一类的中心" ID="2d016779af465205d" STYLE="fork">
		</node>
		<node TEXT="重复上述过程，直到每次新的中心和旧的中心之间的偏移非常小，即过程收敛" ID="25b16779af793900f" STYLE="fork">
		</node>
		</node>
		<node TEXT="如果是凸函数，则能找到全局最优" ID="d116779b055ef01" STYLE="fork">
		</node>
		<node TEXT="但是文本分类中的余弦距离都不保证是凸函数，因此有可能给出的是局部最优" ID="32916779b0ad7e011" STYLE="fork">
		</node>
		</node>
		<node TEXT="逻辑回归和搜索广告" ID="7416779bfe8d3088" STYLE="bubble" POSITION="left">
		<node TEXT="搜索广告三个阶段" ID="1fa16779c02079164" STYLE="fork">
		<node TEXT="早期Overture和百度的广告系统，价高者得" ID="15416779c12cf910d" STYLE="fork">
		</node>
		<node TEXT="谷歌的CTR，关键技术是点击率预估" ID="1d416779c1929c0a8" STYLE="fork">
		</node>
		<node TEXT="进一步的全局优化" ID="28416779c21656027" STYLE="fork">
		</node>
		</node>
		<node TEXT="逻辑回归" ID="17716779c23e0a126" STYLE="fork">
		<node TEXT="采用逻辑回归函数，自变量无穷，值域零到壹" ID="1cf16779c2fa1b197" STYLE="fork">
		</node>
		<node TEXT="拥有一个常量和k个自变量，自己k个自变量系数" ID="33b16779c3f95d0ea" STYLE="fork">
		</node>
		<node TEXT="是一种将影响概率的不同因素结合到一起的指数函数" ID="32916779c5411913" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="云计算" ID="3ad16779c5d9b20b4" STYLE="bubble" POSITION="left">
		<node TEXT="google采用MapReduce，" ID="9a16779c69b1a13a" STYLE="fork">
		</node>
		<node TEXT="本质上是分治的思想" ID="38e1677c4f746a058" STYLE="fork">
		</node>
		</node>
		<node TEXT="Google大脑和人工神经网络" ID="2ba16779c5f904051" STYLE="bubble" POSITION="left">
		<node TEXT="人工神经网络和贝叶斯差不多" ID="3141677c50011d151" STYLE="fork">
		<node TEXT="相同点" ID="1621677c5b5f99083" STYLE="fork">
		<node TEXT="都是有向图，遵循马尔科夫链假设" ID="2e21677c5b77b20f8" STYLE="fork">
		</node>
		<node TEXT="训练方法相似" ID="3201677c5cc6c5126" STYLE="fork">
		</node>
		<node TEXT="模式分类上，这两种方法在效果上相似，很多用神经网络能解决的，贝叶斯网络也能解决，反之亦然" ID="2b21677c5cf2c108c" STYLE="fork">
		</node>
		<node TEXT="计算量大" ID="2c81677c5e91e608" STYLE="fork">
		</node>
		</node>
		<node TEXT="不同点" ID="27d1677c5e60d6095" STYLE="fork">
		<node TEXT="人工神经网络完全标准化，没有贝叶斯灵活" ID="2e61677c5e7bbe0e2" STYLE="fork">
		</node>
		<node TEXT="贝叶斯更容易考虑上下文前后的关系，人工神经网络相对孤立" ID="29f1677c5f1ba3055" STYLE="fork">
		<node TEXT="因此贝叶斯可以用来解码一个输入序列，比如讲一段语音识别成文字，或者将英语句子翻译成中文" ID="3621677c673d9a189" STYLE="fork">
		</node>
		<node TEXT="人工神经网络可以识别一个个字，但是很难处理一个序列。因此主要用于估计一个概率模型的参数" ID="1df1677c680119159" STYLE="fork">
		</node>
		</node>
		</node>
		</node>
		<node TEXT="Google大脑采用人工神经网络的原因" ID="2f91677c6b8aa0072" STYLE="fork">
		<node TEXT="算法稳定" ID="9e1677c6bdabf0f9" STYLE="fork">
		</node>
		<node TEXT="有很好的通用性" ID="431677c6c38e70c6" STYLE="fork">
		</node>
		<node TEXT="容易并行化运算" ID="33d1677c6c647a077" STYLE="fork">
		</node>
		</node>
		</node>
		<node TEXT="大数据的威力" ID="8f1677c6ccb04134" STYLE="bubble" POSITION="left">
		<node TEXT="数据的重要性" ID="3f1677c6ceef4058" STYLE="fork">
		<node TEXT="从有文明就有数据，以前是对过往经验的总结，得出的结论" ID="f01677c73feb20e7" STYLE="fork">
		</node>
		<node TEXT="数据得出的结论有时候和我们&quot;以为&quot;有很大出入" ID="19f1677c74e1320ce" STYLE="fork">
		</node>
		</node>
		<node TEXT="大数据的&quot;大&quot;" ID="5f1677c75a1460ce" STYLE="fork">
		<node TEXT="不只是数据量大，更多的是维度大还有完备性" ID="fd1677c75d0980b3" STYLE="fork">
		</node>
		</node>
		<node TEXT="案例" ID="2851677c7691e50a9" STYLE="fork">
		<node TEXT="Google仅做了一年的自然语言处理就领先其他公司很多年。算法没有多大改进，就是拥有大数据进行分析训练" ID="2261677c76b9c20d9" STYLE="fork">
		</node>
		<node TEXT="Google的搜索前期比Bing好，因为数据集大，便于总结分析。百度搜索比搜狗有道好也是同样道理" ID="3991677c781f870d6" STYLE="fork">
		</node>
		</node>
		<node TEXT="为什么需要大数据" ID="1dd1677c7909cd0bb" STYLE="fork">
		<node TEXT="除了最热的IT行业，现在医疗技术很多都基于大数据，比如分析基因缺陷是否会导致疾病的概率升高。为每个病人个性化制作抗癌药物" ID="371677c7957aa17b" STYLE="fork">
		</node>
		<node TEXT="其他行业也会越来越依赖大数据" ID="1c01677c7df399169" STYLE="fork">
		</node>
		</node>
		</node>
</node>
</map>